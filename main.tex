\documentclass{llncs}		%Petite taille de doc

\usepackage[francais]{babel}	%Doc fr
\usepackage[T1]{fontenc}	%Caracteres accentues
\usepackage[utf8]{inputenc}  
\usepackage{framed}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\begin{document}
\title{Variants of Algorithm to solve the Learning Parities with Noise Problem}
\author{Thomas Bourgeat\inst{1} \and Pierre-Alain Fouque\inst{2} \and Paul Kirchner\inst{1}}
\institute{\'Ecole normale sup\'erieure, 45 rue d'Ulm, 75005 Paris, France \\
\texttt{\{Thomas.Bourgeat,Pierre-Alain.Fouque,Paul.Kirchner\}@ens.fr}
\and 
Universit\'e de Rennes and Institut Universitaire de France}

\maketitle

\begin{abstract}
In this paper, we study some variants of the BKW (Blum-Kalai-Wasserman) algorithm to solve the Learning Parities with Noise (LPN) Problem. Here, we propose to analyse these variants and propose concrete parameters for cryptosystems based on this problem. 
\end{abstract}

\section{Introduction}
The Learning Parities with Noise (LPN) problem is a well-known problem in learning and it is also used in various cryptosystems. Its connection with lattice problem and the average case to hard case reduction for some lattice has been the last years a very active research area and many cryptosystems have been proposed. 

Parler de l'efficacite, LAPIN, ... 

\section{Description of BKW algorithm}

\subsection{BKW}

\subsection{LF algorithm}

decrire la FFT ici

\subsection{Algo de Paul sur eprint}
expliquer la reduction de la memoire

\section{Description of the Algorithm}

decrire le nouvel algo en indiquant les differentes phase grace a un dessin

\subsection{Complexity}
Complexity en fonction de la sparse WH

\section{Sparse Walsh-Hadamard}
Let $f:(\mathbb{Z}/2.\mathbb{Z})^n \rightarrow \mathbb{Z}/2.\mathbb{Z}$.

\subsection{Description}
We know since (TODO:ref) how to compute a fast Walsh-Hadamard transform.
However, to solve the sparse-LPN, we don't need the all spectrum of f. 
A natural question is to wonder if we can adapt the algorithm to compute only
some coefficients of $\hat{f}$. 


The next algorithm generates the list of $(s,score(s))$ for all $s$ potential secret of
hamming weight less or equal to p.p is a parameter of the algorithm.
\begin{framed}
\begin{algorithmic}
%HW :: Set(Sample) -> List(secrets,scores)  
\State p parameter of sparsity
\Function{WH}{Samples,n}
\If{$n=0$} \Return{$[(\epsilon,\sum\limits_{(s,v) \in \text{Samples}} 2v-1)]$}  \EndIf
\State $L_0 \gets \{x | 0.x \in \text{Samples} \}$
\State $L_1 \gets \{x | 1.x \in \text{Samples} \}$
\State $s_0 \gets WH(L_0,n-1)$ 
\State $s_1 \gets WH(L_1,n-1)$
\State$ L \gets []$
\ForAll{ $(s,score_0) \in s_0,(s,score_1) \in s_1 $ } 
  \State $ L\gets L:(0.s, score_0 + score_1)    $
  \If{$weight(1.s) \leq p $} $L\gets L: (1.s ,  score_0 - score_1)  $ \EndIf 
\EndFor
\Return{L}
\EndFunction
\end{algorithmic}
\end{framed}

\subsection{Complexity}

\section{Tables}

\section{Experiments}

\section{Conclusion}

%% References
\bibliographystyle{inc/splncs_srt.bst}
%\bibliographystyle{alpha}
%\bibliographystyle{apalike}
\bibliography{bibliography}

%% Appendix
%\appendix
%\input{appendix.tex}
 



\end{document}
